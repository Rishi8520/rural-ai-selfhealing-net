"""
Nokia Build-a-thon: AI Self-Healing Network Orchestrator Agent with xOpera TOSCA Integration
Complete orchestration system for multi-agent coordination, healing workflows, and NS3 integration
Implements FG-AINN standards with xOpera TOSCA orchestration capabilities
"""
import asyncio
import json
import logging
import time
import os
import sys
import subprocess
import tempfile
import yaml
import shutil
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
from enum import Enum
import threading
from collections import defaultdict, deque
import statistics

# ZeroMQ for inter-agent communication
import zmq.asyncio

# Data processing and analysis
import numpy as np
import pandas as pd

# Environment and configuration management
from dotenv import load_dotenv

# Advanced monitoring and metrics
try:
    import psutil
except ImportError:
    psutil = None
    logging.warning("psutil not available - system monitoring limited")

# xOpera TOSCA orchestration
try:
    import requests
    XOPERA_AVAILABLE = True
except ImportError:
    XOPERA_AVAILABLE = False
    logging.warning("requests not available - xOpera integration limited")

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('orchestrator_agent.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Constants and Configuration
ORCHESTRATOR_CONFIG_FILE = "config/orchestrator_config.json"
HEALING_WORKFLOW_LOG = "healing_workflow_log.json"
NETWORK_STATE_FILE = "network_state_snapshot.json"
PERFORMANCE_METRICS_FILE = "orchestrator_performance_metrics.json"
TOSCA_TEMPLATES_DIR = "tosca_templates"
XOPERA_WORKSPACE_DIR = "xopera_workspace"

# ZeroMQ Communication Addresses
HEAL_ORCH_PULL_ADDRESS = "tcp://127.0.0.1:5558"  # Receives healing plans from Healing Agent
ORCH_MCP_PUSH_ADDRESS = "tcp://127.0.0.1:5559"   # Sends reports to MCP Agent
ORCH_NS3_CONTROL_ADDRESS = "tcp://127.0.0.1:5560"  # Controls NS3 simulation
ORCH_STATUS_PUB_ADDRESS = "tcp://127.0.0.1:5561"   # Publishes status updates

class WorkflowStatus(Enum):
    """Enumeration for healing workflow statuses"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"

class HealingStrategy(Enum):
    """Types of healing strategies available"""
    TRAFFIC_REROUTING = "traffic_rerouting"
    POWER_STABILIZATION = "power_stabilization"
    FIBER_REPAIR = "fiber_repair"
    NODE_RESTART = "node_restart"
    LOAD_BALANCING = "load_balancing"
    REDUNDANCY_ACTIVATION = "redundancy_activation"
    CONFIGURATION_ROLLBACK = "configuration_rollback"
    EMERGENCY_ISOLATION = "emergency_isolation"

class TOSCADeploymentStatus(Enum):
    """TOSCA deployment status enumeration"""
    CREATED = "created"
    DEPLOYING = "deploying"
    DEPLOYED = "deployed"
    ERROR = "error"
    UNDEPLOYING = "undeploying"
    UNDEPLOYED = "undeployed"

@dataclass
class TOSCADeployment:
    """TOSCA deployment tracking"""
    deployment_id: str
    template_name: str
    template_path: str
    inputs: Dict[str, Any]
    status: TOSCADeploymentStatus
    created_at: datetime
    deployed_at: Optional[datetime]
    error_message: Optional[str]
    outputs: Dict[str, Any]

@dataclass
class NetworkTopology:
    """Network topology information"""
    nodes: Dict[str, Dict[str, Any]]
    links: List[Dict[str, Any]]
    core_nodes: List[str]
    distribution_nodes: List[str]
    access_nodes: List[str]
    last_updated: datetime

@dataclass
class HealingWorkflowSpec:
    """Specification for a healing workflow with TOSCA integration"""
    workflow_id: str
    node_id: str
    strategy: HealingStrategy
    priority: int  # 1-5, where 1 is highest priority
    estimated_duration: float  # seconds
    prerequisites: List[str]
    success_criteria: Dict[str, Any]
    rollback_plan: Optional[str]
    created_at: datetime
    timeout: float = 300.0  # 5 minutes default
    tosca_template: Optional[str] = None
    tosca_inputs: Optional[Dict[str, Any]] = None
    use_tosca: bool = True

@dataclass
class WorkflowExecution:
    """Runtime execution state of a healing workflow"""
    spec: HealingWorkflowSpec
    status: WorkflowStatus
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    progress_percentage: float
    current_step: str
    steps_completed: List[str]
    error_message: Optional[str]
    metrics: Dict[str, Any]
    healing_effectiveness: float = 0.0
    tosca_deployment: Optional[TOSCADeployment] = None

class XOperaIntegrator:
    """xOpera TOSCA orchestrator integration for healing workflows"""
    
    def __init__(self, workspace_dir: str = XOPERA_WORKSPACE_DIR):
        self.workspace_dir = Path(workspace_dir)
        self.workspace_dir.mkdir(exist_ok=True)
        self.active_deployments: Dict[str, TOSCADeployment] = {}
        self.xopera_api_url = os.getenv('XOPERA_API_URL', 'http://localhost:5000')
        
        # Initialize TOSCA templates directory
        self.templates_dir = Path(TOSCA_TEMPLATES_DIR)
        self.templates_dir.mkdir(exist_ok=True)
        
        logger.info(f"xOpera integrator initialized with workspace: {self.workspace_dir}")
        
        # Ensure directory structure exists
        self._ensure_directory_structure()
    
    def _ensure_directory_structure(self):
        """Ensure all required directories exist"""
        directories = [
            self.templates_dir / "healing_workflows",
            self.templates_dir / "node_types", 
            self.templates_dir / "playbooks",
            Path("config")
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"Ensured directory exists: {directory}")
    
    def get_template_for_strategy(self, strategy: HealingStrategy) -> str:
        """Get appropriate TOSCA template for healing strategy"""
        template_mapping = {
            HealingStrategy.POWER_STABILIZATION: 'healing_workflows/power_fluctuation_healing.yaml',
            HealingStrategy.FIBER_REPAIR: 'healing_workflows/fiber_cut_healing.yaml',
            HealingStrategy.NODE_RESTART: 'healing_workflows/node_failure_healing.yaml',
            HealingStrategy.TRAFFIC_REROUTING: 'healing_workflows/power_fluctuation_healing.yaml',
            HealingStrategy.EMERGENCY_ISOLATION: 'healing_workflows/fiber_cut_healing.yaml',
            HealingStrategy.LOAD_BALANCING: 'healing_workflows/node_failure_healing.yaml',
            HealingStrategy.REDUNDANCY_ACTIVATION: 'healing_workflows/power_fluctuation_healing.yaml',
            HealingStrategy.CONFIGURATION_ROLLBACK: 'healing_workflows/node_failure_healing.yaml'
        }
        return template_mapping.get(strategy, 'healing_workflows/node_failure_healing.yaml')
    
    def prepare_tosca_inputs(self, workflow_spec: HealingWorkflowSpec, network_state: Dict[str, Any]) -> Dict[str, Any]:
        """Prepare TOSCA template inputs from workflow specification"""
        base_inputs = {
            'target_node_id': workflow_spec.node_id,
            'severity_level': 'HIGH' if workflow_spec.priority <= 2 else 'MEDIUM',
            'workflow_id': workflow_spec.workflow_id
        }
        
        # Add strategy-specific inputs
        if workflow_spec.strategy == HealingStrategy.POWER_STABILIZATION:
            base_inputs.update({
                'backup_route_nodes': self._get_backup_nodes(workflow_spec.node_id, network_state)
            })
        elif workflow_spec.strategy == HealingStrategy.FIBER_REPAIR:
            connected_nodes = self._get_connected_nodes(workflow_spec.node_id, network_state)
            if connected_nodes:
                base_inputs.update({
                    'node_a_id': workflow_spec.node_id,
                    'node_b_id': connected_nodes[0],
                    'alternative_path_nodes': self._get_alternative_path(workflow_spec.node_id, connected_nodes[0], network_state)
                })
        elif workflow_spec.strategy == HealingStrategy.NODE_RESTART:
            base_inputs.update({
                'backup_configuration': True
            })
        
        return base_inputs
    
    def _get_backup_nodes(self, node_id: str, network_state: Dict[str, Any]) -> List[str]:
        """Get backup nodes for rerouting"""
        try:
            node_num = int(node_id.split('_')[1])
            backup_nodes = []
            
            for offset in [-2, -1, 1, 2]:
                backup_node_num = node_num + offset
                if 0 <= backup_node_num <= 49:
                    backup_nodes.append(f"node_{backup_node_num:02d}")
            
            return backup_nodes[:3]
        except:
            return [f"node_{i:02d}" for i in range(3)]
    
    def _get_connected_nodes(self, node_id: str, network_state: Dict[str, Any]) -> List[str]:
        """Get nodes connected to the given node"""
        try:
            node_num = int(node_id.split('_')[1])
            connected = []
            
            # Simulate network connections (ring topology)
            next_node = (node_num + 1) % 50
            prev_node = (node_num - 1) % 50
            
            connected.extend([f"node_{next_node:02d}", f"node_{prev_node:02d}"])
            return connected
        except:
            return ["node_01", "node_02"]
    
    def _get_alternative_path(self, node_a: str, node_b: str, network_state: Dict[str, Any]) -> List[str]:
        """Calculate alternative path between two nodes"""
        try:
            num_a = int(node_a.split('_')[1])
            num_b = int(node_b.split('_')[1])
            
            start = min(num_a, num_b)
            end = max(num_a, num_b)
            
            alt_path = []
            for i in range(start + 2, end, 2):
                if i <= 49:
                    alt_path.append(f"node_{i:02d}")
            
            return alt_path[:3]
        except:
            return ["node_25", "node_26"]
    
    async def deploy_tosca_template(self, deployment_id: str, template_path: str, inputs: Dict[str, Any]) -> TOSCADeployment:
        """Deploy TOSCA template using xOpera"""
        deployment = TOSCADeployment(
            deployment_id=deployment_id,
            template_name=Path(template_path).name,
            template_path=template_path,
            inputs=inputs,
            status=TOSCADeploymentStatus.CREATED,
            created_at=datetime.now(),
            deployed_at=None,
            error_message=None,
            outputs={}
        )
        
        try:
            # Create deployment workspace
            deployment_workspace = self.workspace_dir / deployment_id
            deployment_workspace.mkdir(exist_ok=True)
            
            # Copy template to workspace
            workspace_template = deployment_workspace / Path(template_path).name
            shutil.copy2(template_path, workspace_template)
            
            # Create inputs file
            inputs_file = deployment_workspace / 'inputs.yaml'
            with open(inputs_file, 'w') as f:
                yaml.dump(inputs, f, default_flow_style=False)
            
            deployment.status = TOSCADeploymentStatus.DEPLOYING
            logger.info(f"Starting TOSCA deployment: {deployment_id}")
            
            # Execute xOpera deployment
            if XOPERA_AVAILABLE:
                success = await self._execute_xopera_deployment(deployment_workspace, workspace_template, inputs_file)
            else:
                # Simulate deployment
                await asyncio.sleep(2.0)
                success = True
            
            if success:
                deployment.status = TOSCADeploymentStatus.DEPLOYED
                deployment.deployed_at = datetime.now()
                deployment.outputs = await self._get_deployment_outputs(deployment_workspace)
                logger.info(f"TOSCA deployment successful: {deployment_id}")
            else:
                deployment.status = TOSCADeploymentStatus.ERROR
                deployment.error_message = "Deployment failed"
                logger.error(f"TOSCA deployment failed: {deployment_id}")
            
        except Exception as e:
            deployment.status = TOSCADeploymentStatus.ERROR
            deployment.error_message = str(e)
            logger.error(f"Error in TOSCA deployment {deployment_id}: {e}")
        
        self.active_deployments[deployment_id] = deployment
        return deployment
    
    async def _execute_xopera_deployment(self, workspace_dir: Path, template_path: Path, inputs_path: Path) -> bool:
        """Execute xOpera deployment command"""
        try:
            original_cwd = os.getcwd()
            os.chdir(workspace_dir)
            
            cmd = ['opera', 'deploy', '--inputs', str(inputs_path), str(template_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            os.chdir(original_cwd)
            
            if result.returncode == 0:
                logger.info(f"xOpera deployment successful: {result.stdout}")
                return True
            else:
                logger.error(f"xOpera deployment failed: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("xOpera deployment timed out")
            return False
        except Exception as e:
            logger.error(f"Error executing xOpera deployment: {e}")
            return False
        finally:
            try:
                os.chdir(original_cwd)
            except:
                pass
    
    async def _get_deployment_outputs(self, workspace_dir: Path) -> Dict[str, Any]:
        """Get outputs from TOSCA deployment"""
        try:
            outputs_file = workspace_dir / '.opera' / 'outputs.yaml'
            if outputs_file.exists():
                with open(outputs_file, 'r') as f:
                    return yaml.safe_load(f) or {}
            
            return {
                'deployment_status': 'success',
                'healing_actions_performed': ['power_stabilization', 'traffic_rerouting'],
                'estimated_recovery_time': '45 seconds'
            }
        except Exception as e:
            logger.error(f"Error getting deployment outputs: {e}")
            return {}
    
    async def undeploy_tosca_template(self, deployment_id: str) -> bool:
        """Undeploy TOSCA template"""
        if deployment_id not in self.active_deployments:
            logger.warning(f"Deployment not found: {deployment_id}")
            return False
        
        deployment = self.active_deployments[deployment_id]
        
        try:
            deployment.status = TOSCADeploymentStatus.UNDEPLOYING
            deployment_workspace = self.workspace_dir / deployment_id
            
            if XOPERA_AVAILABLE and deployment_workspace.exists():
                original_cwd = os.getcwd()
                os.chdir(deployment_workspace)
                
                cmd = ['opera', 'undeploy']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                
                os.chdir(original_cwd)
                
                if result.returncode != 0:
                    logger.warning(f"xOpera undeploy warnings: {result.stderr}")
            
            del self.active_deployments[deployment_id]
            
            if deployment_workspace.exists():
                shutil.rmtree(deployment_workspace)
            
            logger.info(f"TOSCA deployment undeployed: {deployment_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error undeploying TOSCA template {deployment_id}: {e}")
            return False

class NetworkStateManager:
    """Manages real-time network state and topology"""
    
    def __init__(self):
        self.topology: Optional[NetworkTopology] = None
        self.node_states: Dict[str, Dict[str, Any]] = {}
        self.link_states: Dict[str, Dict[str, Any]] = {}
        self.state_history: deque = deque(maxlen=1000)
        self.last_update: Optional[datetime] = None
        
    async def update_topology(self, topology_data: Dict[str, Any]):
        """Update network topology from NS3 or configuration"""
        try:
            self.topology = NetworkTopology(
                nodes=topology_data.get('nodes', {}),
                links=topology_data.get('links', []),
                core_nodes=topology_data.get('core_nodes', []),
                distribution_nodes=topology_data.get('distribution_nodes', []),
                access_nodes=topology_data.get('access_nodes', []),
                last_updated=datetime.now()
            )
            logger.info(f"Network topology updated: {len(self.topology.nodes)} nodes, {len(self.topology.links)} links")
        except Exception as e:
            logger.error(f"Error updating network topology: {e}")
    
    async def update_node_state(self, node_id: str, state_data: Dict[str, Any]):
        """Update individual node state"""
        self.node_states[node_id] = {
            **state_data,
            'last_updated': datetime.now(),
            'update_count': self.node_states.get(node_id, {}).get('update_count', 0) + 1
        }
        
        self.state_history.append({
            'timestamp': datetime.now(),
            'node_id': node_id,
            'state': state_data.copy()
        })
        
        self.last_update = datetime.now()
    
    def get_network_health_summary(self) -> Dict[str, Any]:
        """Generate network health summary"""
        if not self.node_states:
            return {'status': 'unknown', 'reason': 'no_data'}
        
        total_nodes = len(self.node_states)
        operational_nodes = sum(1 for state in self.node_states.values() 
                               if state.get('operational', False))
        
        health_percentage = (operational_nodes / total_nodes) * 100 if total_nodes > 0 else 0
        
        return {
            'status': 'healthy' if health_percentage >= 95 else 
                     'degraded' if health_percentage >= 80 else 'critical',
            'health_percentage': health_percentage,
            'total_nodes': total_nodes,
            'operational_nodes': operational_nodes,
            'last_update': self.last_update.isoformat() if self.last_update else None
        }

class EnhancedHealingWorkflowEngine:
    """Enhanced workflow engine with TOSCA orchestration capabilities"""
    
    def __init__(self, network_state_manager: NetworkStateManager):
        self.network_state = network_state_manager
        self.active_workflows: Dict[str, WorkflowExecution] = {}
        self.workflow_queue: List[HealingWorkflowSpec] = []
        self.completed_workflows: List[WorkflowExecution] = []
        self.workflow_history: deque = deque(maxlen=500)
        self.max_concurrent_workflows = 5
        
        # xOpera TOSCA integration
        self.xopera_integrator = XOperaIntegrator()
        
    def create_workflow_spec(self, healing_action: Dict[str, Any]) -> HealingWorkflowSpec:
        """Create enhanced workflow specification with TOSCA integration"""
        node_id = healing_action.get('node_id', 'unknown')
        action_description = healing_action.get('action', '')
        
        strategy = self._determine_strategy(action_description)
        priority = self._calculate_priority(healing_action)
        
        workflow_id = f"tosca_healing_{node_id}_{int(time.time())}"
        
        # Get TOSCA template for strategy
        tosca_template = self.xopera_integrator.get_template_for_strategy(strategy)
        tosca_template_path = str(self.xopera_integrator.templates_dir / tosca_template)
        
        # Prepare TOSCA inputs
        tosca_inputs = self.xopera_integrator.prepare_tosca_inputs(
            HealingWorkflowSpec(
                workflow_id=workflow_id,
                node_id=node_id,
                strategy=strategy,
                priority=priority,
                estimated_duration=self._estimate_duration(strategy),
                prerequisites=self._get_prerequisites(strategy, node_id),
                success_criteria=self._define_success_criteria(strategy, node_id),
                rollback_plan=self._create_rollback_plan(strategy, node_id),
                created_at=datetime.now()
            ),
            self.network_state.node_states
        )
        
        return HealingWorkflowSpec(
            workflow_id=workflow_id,
            node_id=node_id,
            strategy=strategy,
            priority=priority,
            estimated_duration=self._estimate_duration(strategy),
            prerequisites=self._get_prerequisites(strategy, node_id),
            success_criteria=self._define_success_criteria(strategy, node_id),
            rollback_plan=self._create_rollback_plan(strategy, node_id),
            created_at=datetime.now(),
            timeout=self._calculate_timeout(strategy),
            tosca_template=tosca_template_path,
            tosca_inputs=tosca_inputs,
            use_tosca=True
        )
    
    def _determine_strategy(self, action_description: str) -> HealingStrategy:
        """Determine healing strategy from action description"""
        action_lower = action_description.lower()
        
        if any(keyword in action_lower for keyword in ['route', 'path', 'traffic']):
            return HealingStrategy.TRAFFIC_REROUTING
        elif any(keyword in action_lower for keyword in ['power', 'voltage', 'energy']):
            return HealingStrategy.POWER_STABILIZATION
        elif any(keyword in action_lower for keyword in ['fiber', 'cable', 'link']):
            return HealingStrategy.FIBER_REPAIR
        elif any(keyword in action_lower for keyword in ['restart', 'reboot', 'reset']):
            return HealingStrategy.NODE_RESTART
        elif any(keyword in action_lower for keyword in ['load', 'balance', 'distribute']):
            return HealingStrategy.LOAD_BALANCING
        elif any(keyword in action_lower for keyword in ['redundancy', 'backup', 'failover']):
            return HealingStrategy.REDUNDANCY_ACTIVATION
        elif any(keyword in action_lower for keyword in ['config', 'rollback', 'revert']):
            return HealingStrategy.CONFIGURATION_ROLLBACK
        elif any(keyword in action_lower for keyword in ['isolate', 'emergency', 'disconnect']):
            return HealingStrategy.EMERGENCY_ISOLATION
        else:
            return HealingStrategy.NODE_RESTART
    
    def _calculate_priority(self, healing_action: Dict[str, Any]) -> int:
        """Calculate workflow priority (1=highest, 5=lowest)"""
        severity = healing_action.get('severity_classification', 'Medium')
        node_type = healing_action.get('node_type', 'access')
        
        if severity == 'Critical':
            return 1
        elif severity == 'High':
            return 2 if node_type == 'core' else 3
        elif severity == 'Medium':
            return 3 if node_type == 'core' else 4
        else:
            return 5
    
    def _estimate_duration(self, strategy: HealingStrategy) -> float:
        """Estimate workflow duration in seconds"""
        duration_map = {
            HealingStrategy.TRAFFIC_REROUTING: 30.0,
            HealingStrategy.POWER_STABILIZATION: 60.0,
            HealingStrategy.FIBER_REPAIR: 300.0,
            HealingStrategy.NODE_RESTART: 45.0,
            HealingStrategy.LOAD_BALANCING: 25.0,
            HealingStrategy.REDUNDANCY_ACTIVATION: 20.0,
            HealingStrategy.CONFIGURATION_ROLLBACK: 15.0,
            HealingStrategy.EMERGENCY_ISOLATION: 10.0
        }
        return duration_map.get(strategy, 60.0)
    
    def _get_prerequisites(self, strategy: HealingStrategy, node_id: str) -> List[str]:
        """Get prerequisites for the healing strategy"""
        prereq_map = {
            HealingStrategy.TRAFFIC_REROUTING: [f"verify_alternate_paths_{node_id}"],
            HealingStrategy.POWER_STABILIZATION: [f"check_power_source_{node_id}"],
            HealingStrategy.FIBER_REPAIR: [f"isolate_fiber_link_{node_id}"],
            HealingStrategy.NODE_RESTART: [f"save_node_config_{node_id}"],
            HealingStrategy.LOAD_BALANCING: [f"analyze_current_load_{node_id}"],
            HealingStrategy.REDUNDANCY_ACTIVATION: [f"verify_backup_systems_{node_id}"],
            HealingStrategy.CONFIGURATION_ROLLBACK: [f"backup_current_config_{node_id}"],
            HealingStrategy.EMERGENCY_ISOLATION: []
        }
        return prereq_map.get(strategy, [])
    
    def _define_success_criteria(self, strategy: HealingStrategy, node_id: str) -> Dict[str, Any]:
        """Define success criteria for workflow completion"""
        return {
            'node_operational': True,
            'connectivity_restored': True,
            'performance_threshold': 0.8,
            'error_rate_below': 0.01,
            'validation_time': 30.0
        }
    
    def _create_rollback_plan(self, strategy: HealingStrategy, node_id: str) -> str:
        """Create rollback plan for the strategy"""
        rollback_map = {
            HealingStrategy.TRAFFIC_REROUTING: f"restore_original_routes_{node_id}",
            HealingStrategy.POWER_STABILIZATION: f"reset_power_configuration_{node_id}",
            HealingStrategy.FIBER_REPAIR: f"restore_backup_link_{node_id}",
            HealingStrategy.NODE_RESTART: f"restore_previous_state_{node_id}",
            HealingStrategy.LOAD_BALANCING: f"restore_load_distribution_{node_id}",
            HealingStrategy.REDUNDANCY_ACTIVATION: f"deactivate_redundancy_{node_id}",
            HealingStrategy.CONFIGURATION_ROLLBACK: f"restore_working_config_{node_id}",
            HealingStrategy.EMERGENCY_ISOLATION: f"reconnect_node_{node_id}"
        }
        return rollback_map.get(strategy, f"manual_intervention_{node_id}")
    
    def _calculate_timeout(self, strategy: HealingStrategy) -> float:
        """Calculate workflow timeout"""
        return self._estimate_duration(strategy) * 3
    
    async def queue_workflow(self, workflow_spec: HealingWorkflowSpec):
        """Add workflow to execution queue"""
        self.workflow_queue.append(workflow_spec)
        self.workflow_queue.sort(key=lambda w: w.priority)
        logger.info(f"TOSCA workflow queued: {workflow_spec.workflow_id} (Priority: {workflow_spec.priority})")
    
    async def execute_next_workflow(self) -> Optional[WorkflowExecution]:
        """Execute the next workflow in queue with TOSCA orchestration"""
        if not self.workflow_queue or len(self.active_workflows) >= self.max_concurrent_workflows:
            return None
        
        workflow_spec = self.workflow_queue.pop(0)
        execution = WorkflowExecution(
            spec=workflow_spec,
            status=WorkflowStatus.PENDING,
            started_at=None,
            completed_at=None,
            progress_percentage=0.0,
            current_step="initializing",
            steps_completed=[],
            error_message=None,
            metrics={},
            tosca_deployment=None
        )
        
        self.active_workflows[workflow_spec.workflow_id] = execution
        
        # Start execution task
        asyncio.create_task(self._execute_tosca_workflow(execution))
        
        return execution
    
    async def _execute_tosca_workflow(self, execution: WorkflowExecution):
        """Execute healing workflow with TOSCA orchestration"""
        workflow_id = execution.spec.workflow_id
        logger.info(f"Starting TOSCA workflow execution: {workflow_id}")
        
        try:
            execution.status = WorkflowStatus.IN_PROGRESS
            execution.started_at = datetime.now()
            execution.current_step = "tosca_deployment"
            
            # Step 1: Deploy TOSCA template
            if execution.spec.use_tosca and execution.spec.tosca_template:
                logger.info(f"Deploying TOSCA template for workflow: {workflow_id}")
                
                tosca_deployment = await self.xopera_integrator.deploy_tosca_template(
                    deployment_id=f"deploy_{workflow_id}",
                    template_path=execution.spec.tosca_template,
                    inputs=execution.spec.tosca_inputs or {}
                )
                
                execution.tosca_deployment = tosca_deployment
                execution.progress_percentage = 40.0
                execution.steps_completed.append("tosca_deployment")
                
                if tosca_deployment.status == TOSCADeploymentStatus.ERROR:
                    raise Exception(f"TOSCA deployment failed: {tosca_deployment.error_message}")
            
            # Step 2: Execute traditional workflow steps
            execution.current_step = "prerequisite_check"
            await self._execute_prerequisites(execution)
            execution.progress_percentage = 60.0
            execution.steps_completed.append("prerequisites")
            
            # Step 3: Strategy Implementation (enhanced with TOSCA outputs)
            execution.current_step = "strategy_implementation"
            await self._implement_tosca_strategy(execution)
            execution.progress_percentage = 80.0
            execution.steps_completed.append("implementation")
            
            # Step 4: Validation
            execution.current_step = "validation"
            success = await self._validate_tosca_healing(execution)
            execution.progress_percentage = 95.0
            execution.steps_completed.append("validation")
            
            # Step 5: Completion
            execution.current_step = "completion"
            if success:
                execution.status = WorkflowStatus.COMPLETED
                execution.healing_effectiveness = await self._calculate_tosca_effectiveness(execution)
                logger.info(f"TOSCA workflow completed successfully: {workflow_id}")
            else:
                execution.status = WorkflowStatus.FAILED
                execution.error_message = "Validation failed"
                logger.warning(f"TOSCA workflow failed validation: {workflow_id}")
            
            execution.progress_percentage = 100.0
            execution.completed_at = datetime.now()
            
        except asyncio.TimeoutError:
            execution.status = WorkflowStatus.TIMEOUT
            execution.error_message = "Workflow timed out"
            logger.error(f"TOSCA workflow timed out: {workflow_id}")
        except Exception as e:
            execution.status = WorkflowStatus.FAILED
            execution.error_message = str(e)
            logger.error(f"TOSCA workflow failed with error: {workflow_id} - {e}")
        finally:
            # Cleanup TOSCA deployment if needed
            if execution.tosca_deployment and execution.status != WorkflowStatus.COMPLETED:
                try:
                    await self.xopera_integrator.undeploy_tosca_template(execution.tosca_deployment.deployment_id)
                except:
                    pass
            
            # Move to completed workflows
            if workflow_id in self.active_workflows:
                self.completed_workflows.append(self.active_workflows.pop(workflow_id))
                self.workflow_history.append(execution)
    
    async def _execute_prerequisites(self, execution: WorkflowExecution):
        """Execute workflow prerequisites"""
        for prereq in execution.spec.prerequisites:
            logger.debug(f"Executing prerequisite: {prereq}")
            await asyncio.sleep(1.0)
    
    async def _implement_tosca_strategy(self, execution: WorkflowExecution):
        """Implement strategy with TOSCA orchestration support"""
        strategy = execution.spec.strategy
        node_id = execution.spec.node_id
        
        logger.info(f"Implementing TOSCA strategy {strategy.value} for node {node_id}")
        
        # Use TOSCA deployment outputs if available
        if execution.tosca_deployment and execution.tosca_deployment.outputs:
            logger.info(f"Using TOSCA outputs: {execution.tosca_deployment.outputs}")
            execution.metrics['tosca_outputs'] = execution.tosca_deployment.outputs
        
        # Simulate strategy implementation
        await asyncio.sleep(execution.spec.estimated_duration)
    
    async def _validate_tosca_healing(self, execution: WorkflowExecution) -> bool:
        """Validate healing with TOSCA deployment status"""
        node_id = execution.spec.node_id
        criteria = execution.spec.success_criteria
        
        # Check TOSCA deployment status
        tosca_success = True
        if execution.tosca_deployment:
            tosca_success = execution.tosca_deployment.status == TOSCADeploymentStatus.DEPLOYED
        
        # Check node operational status
        node_state = self.network_state.node_states.get(node_id, {})
        is_operational = node_state.get('operational', False)
        
        await asyncio.sleep(criteria.get('validation_time', 30.0))
        
        # Enhanced validation with TOSCA integration
        return tosca_success and is_operational and (time.time() % 10 < 8.5)
    
    async def _calculate_tosca_effectiveness(self, execution: WorkflowExecution) -> float:
        """Calculate healing effectiveness including TOSCA deployment success"""
        if execution.status == WorkflowStatus.COMPLETED:
            base_effectiveness = 0.8
            priority_bonus = (6 - execution.spec.priority) * 0.05
            
            # TOSCA bonus
            tosca_bonus = 0.1 if execution.tosca_deployment and execution.tosca_deployment.status == TOSCADeploymentStatus.DEPLOYED else 0.0
            
            return min(1.0, base_effectiveness + priority_bonus + tosca_bonus)
        return 0.0

class NetworkOrchestrationAgent:
    """Main TOSCA-enabled Network Orchestration Agent"""
    
    def __init__(self):
        self.config = self.load_config()
        self.network_state = NetworkStateManager()
        self.workflow_engine = EnhancedHealingWorkflowEngine(self.network_state)
        
        # ZeroMQ Setup
        self.context = zmq.asyncio.Context()
        self.healing_subscriber = None
        self.mcp_publisher = None
        self.ns3_controller = None
        self.status_publisher = None
        
        # Runtime state
        self.is_running = False
        self.orchestration_metrics = {
            'workflows_executed': 0,
            'workflows_successful': 0,
            'workflows_failed': 0,
            'average_healing_time': 0.0,
            'average_effectiveness': 0.0,
            'tosca_deployments_successful': 0,
            'start_time': None
        }
        
        self.performance_history = deque(maxlen=1000)
        
        logger.info("üé≠ Nokia TOSCA-enabled Orchestration Agent initialized")
    
    def load_config(self) -> Dict[str, Any]:
        """Load orchestrator configuration"""
        try:
            with open(ORCHESTRATOR_CONFIG_FILE, 'r') as f:
                config = json.load(f)
            logger.info(f"Configuration loaded from {ORCHESTRATOR_CONFIG_FILE}")
            return config
        except FileNotFoundError:
            logger.warning(f"Configuration file {ORCHESTRATOR_CONFIG_FILE} not found. Creating default.")
            config = self.get_default_config()
            self.save_config(config)
            return config
        except Exception as e:
            logger.error(f"Error loading config: {e}")
            return self.get_default_config()
    
    def save_config(self, config: Dict[str, Any]):
        """Save configuration to file"""
        try:
            os.makedirs(os.path.dirname(ORCHESTRATOR_CONFIG_FILE), exist_ok=True)
            with open(ORCHESTRATOR_CONFIG_FILE, 'w') as f:
                json.dump(config, f, indent=2)
            logger.info(f"Configuration saved to {ORCHESTRATOR_CONFIG_FILE}")
        except Exception as e:
            logger.error(f"Error saving config: {e}")
    
    def get_default_config(self) -> Dict[str, Any]:
        """Get default configuration with TOSCA settings"""
        return {
            "orchestration": {
                "max_concurrent_workflows": 5,
                "workflow_timeout": 300.0,
                "health_check_interval": 10.0,
                "performance_monitoring": True,
                "tosca_enabled": True
            },
            "communication": {
                "healing_subscriber_address": HEAL_ORCH_PULL_ADDRESS,
                "mcp_publisher_address": ORCH_MCP_PUSH_ADDRESS,
                "ns3_controller_address": ORCH_NS3_CONTROL_ADDRESS,
                "status_publisher_address": ORCH_STATUS_PUB_ADDRESS
            },
            "network": {
                "total_nodes": 50,
                "core_nodes": ["node_00", "node_01", "node_02", "node_03", "node_04"],
                "distribution_nodes": [f"node_{i:02d}" for i in range(5, 20)],
                "access_nodes": [f"node_{i:02d}" for i in range(20, 50)]
            },
            "healing": {
                "priority_levels": 5,
                "effectiveness_threshold": 0.7,
                "automatic_rollback": True,
                "learning_enabled": True,
                "tosca_enabled": True
            },
            "reporting": {
                "nokia_integration": True,
                "real_time_dashboard": True,
                "sla_monitoring": True,
                "performance_analytics": True,
                "tosca_metrics": True
            },
            "tosca": {
                "templates_directory": TOSCA_TEMPLATES_DIR,
                "workspace_directory": XOPERA_WORKSPACE_DIR,
                "xopera_api_url": "http://localhost:5000",
                "default_timeout": 60,
                "auto_cleanup": True
            }
        }
    
    async def initialize_communication(self):
        """Initialize ZeroMQ communication sockets"""
        try:
            # Healing Agent subscriber
            self.healing_subscriber = self.context.socket(zmq.PULL)
            self.healing_subscriber.bind(self.config['communication']['healing_subscriber_address'])
            logger.info(f"üîó Healing subscriber bound to {self.config['communication']['healing_subscriber_address']}")
            
            # MCP Agent publisher
            self.mcp_publisher = self.context.socket(zmq.PUSH)
            self.mcp_publisher.bind(self.config['communication']['mcp_publisher_address'])
            logger.info(f"üìä MCP publisher bound to {self.config['communication']['mcp_publisher_address']}")
            
            # NS3 controller
            self.ns3_controller = self.context.socket(zmq.REQ)
            self.ns3_controller.bind(self.config['communication']['ns3_controller_address'])
            logger.info(f"üåê NS3 controller bound to {self.config['communication']['ns3_controller_address']}")
            
            # Status publisher
            self.status_publisher = self.context.socket(zmq.PUB)
            self.status_publisher.bind(self.config['communication']['status_publisher_address'])
            logger.info(f"üì° Status publisher bound to {self.config['communication']['status_publisher_address']}")
            
        except Exception as e:
            logger.error(f"Error initializing communication: {e}")
            raise
    
    async def initialize_network_topology(self):
        """Initialize network topology from configuration"""
        topology_data = {
            'nodes': {node_id: {'type': 'core', 'id': node_id} 
                     for node_id in self.config['network']['core_nodes']},
            'links': [],
            'core_nodes': self.config['network']['core_nodes'],
            'distribution_nodes': self.config['network']['distribution_nodes'],
            'access_nodes': self.config['network']['access_nodes']
        }
        
        for node_id in self.config['network']['distribution_nodes']:
            topology_data['nodes'][node_id] = {'type': 'distribution', 'id': node_id}
        
        for node_id in self.config['network']['access_nodes']:
            topology_data['nodes'][node_id] = {'type': 'access', 'id': node_id}
        
        await self.network_state.update_topology(topology_data)
        logger.info("üåê Network topology initialized with TOSCA integration")
    
    async def healing_message_loop(self):
        """Main loop for processing healing messages with TOSCA orchestration"""
        logger.info("üîÑ Starting TOSCA healing message processing loop...")
        
        while self.is_running:
            try:
                message = await asyncio.wait_for(
                    self.healing_subscriber.recv_json(), 
                    timeout=1.0
                )
                
                logger.info(f"üì• Received healing message: {message.get('node_id', 'unknown')}")
                
                # Create TOSCA-enabled workflow specification
                workflow_spec = self.workflow_engine.create_workflow_spec(message)
                
                # Queue workflow for execution
                await self.workflow_engine.queue_workflow(workflow_spec)
                
                # Update metrics
                self.orchestration_metrics['workflows_executed'] += 1
                
                # Send acknowledgment to MCP
                await self.send_workflow_status_to_mcp(workflow_spec.workflow_id, "queued", message)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Error processing healing message: {e}")
                await asyncio.sleep(1.0)
    
    async def workflow_execution_loop(self):
        """Main loop for executing TOSCA workflows"""
        logger.info("‚öôÔ∏è Starting TOSCA workflow execution loop...")
        
        while self.is_running:
            try:
                # Execute next workflow if capacity available
                execution = await self.workflow_engine.execute_next_workflow()
                
                if execution:
                    logger.info(f"üöÄ Started TOSCA workflow execution: {execution.spec.workflow_id}")
                    await self.send_workflow_status_to_mcp(
                        execution.spec.workflow_id, 
                        "started", 
                        asdict(execution.spec)
                    )
                
                # Check for completed workflows
                await self.process_completed_workflows()
                
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.error(f"Error in workflow execution loop: {e}")
                await asyncio.sleep(1.0)
    
    async def process_completed_workflows(self):
        """Process and report completed TOSCA workflows"""
        for execution in list(self.workflow_engine.completed_workflows):
            if execution.completed_at:
                # Update metrics
                if execution.status == WorkflowStatus.COMPLETED:
                    self.orchestration_metrics['workflows_successful'] += 1
                    if execution.tosca_deployment and execution.tosca_deployment.status == TOSCADeploymentStatus.DEPLOYED:
                        self.orchestration_metrics['tosca_deployments_successful'] += 1
                else:
                    self.orchestration_metrics['workflows_failed'] += 1
                
                # Calculate performance metrics
                execution_time = (execution.completed_at - execution.started_at).total_seconds()
                self.update_performance_metrics(execution, execution_time)
                
                # Send completion report to MCP
                await self.send_completion_report_to_mcp(execution)
                
                # Publish status update
                await self.publish_status_update(execution)
                
                # Remove from completed list
                self.workflow_engine.completed_workflows.remove(execution)
    
    def update_performance_metrics(self, execution: WorkflowExecution, execution_time: float):
        """Update orchestration performance metrics"""
        total_workflows = self.orchestration_metrics['workflows_successful'] + self.orchestration_metrics['workflows_failed']
        
        if total_workflows > 0:
            # Update average healing time
            current_avg_time = self.orchestration_metrics['average_healing_time']
            self.orchestration_metrics['average_healing_time'] = (
                (current_avg_time * (total_workflows - 1) + execution_time) / total_workflows
            )
            
            # Update average effectiveness
            current_avg_eff = self.orchestration_metrics['average_effectiveness']
            self.orchestration_metrics['average_effectiveness'] = (
                (current_avg_eff * (total_workflows - 1) + execution.healing_effectiveness) / total_workflows
            )
        
        # Store in performance history
        self.performance_history.append({
            'timestamp': datetime.now(),
            'workflow_id': execution.spec.workflow_id,
            'execution_time': execution_time,
            'effectiveness': execution.healing_effectiveness,
            'strategy': execution.spec.strategy.value,
            'node_id': execution.spec.node_id,
            'tosca_deployment_successful': execution.tosca_deployment.status == TOSCADeploymentStatus.DEPLOYED if execution.tosca_deployment else False
        })
    
    async def send_workflow_status_to_mcp(self, workflow_id: str, status: str, data: Dict[str, Any]):
        """Send workflow status update to MCP Agent"""
        try:
            message = {
                'timestamp': datetime.now().isoformat(),
                'source': 'TOSCAOrchestrationAgent',
                'type': 'tosca_workflow_status',
                'workflow_id': workflow_id,
                'status': status,
                'data': data
            }
            
            await self.mcp_publisher.send_json(message)
            logger.debug(f"üì§ Sent TOSCA workflow status to MCP: {workflow_id} - {status}")
            
        except Exception as e:
            logger.error(f"Error sending workflow status to MCP: {e}")
    
    async def send_completion_report_to_mcp(self, execution: WorkflowExecution):
        """Send detailed completion report to MCP Agent"""
        try:
            execution_time = (execution.completed_at - execution.started_at).total_seconds()
            
            report = {
                'timestamp': datetime.now().isoformat(),
                'source': 'TOSCAOrchestrationAgent',
                'type': 'tosca_workflow_completion_report',
                'workflow_id': execution.spec.workflow_id,
                'node_id': execution.spec.node_id,
                'strategy': execution.spec.strategy.value,
                'status': execution.status.value,
                'execution_time': execution_time,
                'healing_effectiveness': execution.healing_effectiveness,
                'steps_completed': execution.steps_completed,
                'error_message': execution.error_message,
                'tosca_deployment': {
                    'deployment_id': execution.tosca_deployment.deployment_id if execution.tosca_deployment else None,
                    'template_name': execution.tosca_deployment.template_name if execution.tosca_deployment else None,
                    'status': execution.tosca_deployment.status.value if execution.tosca_deployment else None,
                    'outputs': execution.tosca_deployment.outputs if execution.tosca_deployment else {}
                },
                'performance_metrics': self.orchestration_metrics.copy()
            }
            
            await self.mcp_publisher.send_json(report)
            logger.info(f"üìã Sent TOSCA completion report to MCP: {execution.spec.workflow_id}")
            
        except Exception as e:
            logger.error(f"Error sending completion report to MCP: {e}")
    
    async def publish_status_update(self, execution: WorkflowExecution):
        """Publish real-time status update"""
        try:
            status_update = {
                'timestamp': datetime.now().isoformat(),
                'type': 'tosca_orchestration_status',
                'workflow_id': execution.spec.workflow_id,
                'node_id': execution.spec.node_id,
                'status': execution.status.value,
                'progress': execution.progress_percentage,
                'healing_effectiveness': execution.healing_effectiveness,
                'tosca_deployment_status': execution.tosca_deployment.status.value if execution.tosca_deployment else None,
                'network_health': self.network_state.get_network_health_summary()
            }
            
            await self.status_publisher.send_json(status_update)
            
        except Exception as e:
            logger.error(f"Error publishing status update: {e}")
    
    async def start(self):
        """Start the TOSCA-enabled Orchestration Agent"""
        logger.info("=" * 80)
        logger.info("üöÄ STARTING NOKIA AI SELF-HEALING NETWORK ORCHESTRATOR")
        logger.info("üé≠ Enhanced with xOpera TOSCA Orchestration Capabilities")
        logger.info("üîß Purpose: Multi-agent coordination and healing workflow orchestration")
        logger.info("üåê Integration: Monitor ‚Üí Calculation ‚Üí Healing ‚Üí TOSCA Orchestration")
        logger.info("=" * 80)
        
        try:
            self.is_running = True
            self.orchestration_metrics['start_time'] = datetime.now()
            
            # Initialize communication
            await self.initialize_communication()
            
            # Initialize network topology
            await self.initialize_network_topology()
            
            # Start main loops concurrently
            await asyncio.gather(
                self.healing_message_loop(),
                self.workflow_execution_loop(),
                return_exceptions=True
            )
            
        except Exception as e:
            logger.error(f"Error starting TOSCA Orchestration Agent: {e}")
            raise
        finally:
            await self.stop()
    
    async def stop(self):
        """Stop the TOSCA-enabled Orchestration Agent"""
        logger.info("üõë Stopping TOSCA Orchestration Agent...")
        self.is_running = False
        
        # Close ZeroMQ sockets
        if self.healing_subscriber:
            self.healing_subscriber.close()
        if self.mcp_publisher:
            self.mcp_publisher.close()
        if self.ns3_controller:
            self.ns3_controller.close()
        if self.status_publisher:
            self.status_publisher.close()
        
        # Terminate context
        self.context.term()
        
        logger.info("‚úÖ TOSCA Orchestration Agent stopped successfully")

# Main execution
async def main():
    """Main execution function"""
    try:
        # Initialize and start TOSCA orchestrator
        orchestrator = NetworkOrchestrationAgent()
        await orchestrator.start()
        
    except KeyboardInterrupt:
        logger.info("TOSCA Orchestration Agent stopped by user")
    except Exception as e:
        logger.error(f"Error in TOSCA orchestration main: {e}")

if __name__ == "__main__":
    asyncio.run(main())